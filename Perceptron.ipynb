{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron Model for OCR and Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR on Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 16)\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read the file\n",
    "file_path = 'digitdata/trainingimages'  # Replace with the path to your digits file\n",
    "with open(file_path, 'rb') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize variables\n",
    "image_data = []\n",
    "images = []\n",
    "\n",
    "# Parse the lines and populate the list of images\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.decode()  # Convert bytes to string and remove newline character\n",
    "    lineSplit= line.split(\"\\n\")\n",
    "    line = \"\".join(lineSplit)\n",
    "    \n",
    "    # Check for non-empty line\n",
    "    if line:\n",
    "        row_data = [1 if c == '#' else 0 for c in line]  # Convert symbols to pixel values\n",
    "        image_data.append(row_data)\n",
    "        \n",
    "        # Check for end of image (28 lines)\n",
    "        if len(image_data) == 28:\n",
    "            # Convert the list of lists (28x28) to a numpy array\n",
    "            image_array = np.array(image_data)\n",
    "            \n",
    "            # Extract features by counting 0s in each 7x7 square\n",
    "            features = []\n",
    "            for i in range(0, 28, 7):\n",
    "                for j in range(0, 28, 7):\n",
    "                    square = image_array[i:i+7, j:j+7]\n",
    "                    count_zeros = np.sum(square == 1)\n",
    "                    features.append(count_zeros)\n",
    "            \n",
    "            # Flatten the 4x4 feature matrix\n",
    "            features = np.array(features).flatten()\n",
    "            \n",
    "            images.append(features)\n",
    "            image_data = []  # Reset image_data\n",
    "    else:\n",
    "        # Check for start of new image (empty line followed by line with symbols)\n",
    "        if i < len(lines) - 1 and lines[i + 1].decode():  # Check if next line is not empty\n",
    "            image_data = []  # Reset image_data\n",
    "\n",
    "# Convert the list of images to a matrix\n",
    "X = np.array(images)\n",
    "print(X.shape)  # Should print (number_of_images, 16)\n",
    "\n",
    "\n",
    "fileLab = 'digitdata/traininglabels'\n",
    "with open(fileLab, 'rb') as file:\n",
    "    lineLab = file.readlines()\n",
    "labels = []\n",
    "for i, line in enumerate(lineLab):\n",
    "    line = line.decode()\n",
    "    lineSplit= line.split(\"\\n\")\n",
    "    line = \"\".join(lineSplit)\n",
    "    labels.append(int(line))\n",
    "Y = labels\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ... 10  0  0]\n",
      " [ 0  1 10 ...  7 12  0]\n",
      " [ 0  6 18 ... 13  4  0]\n",
      " ...\n",
      " [ 0  4  7 ... 10  9  0]\n",
      " [ 0  0  3 ...  0  7  0]\n",
      " [ 0  0  3 ...  7  9  0]]\n",
      "(1000, 16)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read the file\n",
    "file_path = 'digitdata/testimages'  # Replace with the path to your digits file\n",
    "with open(file_path, 'rb') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize variables\n",
    "image_data = []\n",
    "images = []\n",
    "\n",
    "# Parse the lines and populate the list of images\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.decode()  # Convert bytes to string and remove newline character\n",
    "    lineSplit= line.split(\"\\n\")\n",
    "    line = \"\".join(lineSplit)\n",
    "    \n",
    "    # Check for non-empty line\n",
    "    if line:\n",
    "        row_data = [1 if c == '#' else 0 for c in line]  # Convert symbols to pixel values\n",
    "        image_data.append(row_data)\n",
    "        \n",
    "        # Check for end of image (28 lines)\n",
    "        if len(image_data) == 28:\n",
    "            # Convert the list of lists (28x28) to a numpy array\n",
    "            image_array = np.array(image_data)\n",
    "            \n",
    "            # Extract features by counting 0s in each 7x7 square\n",
    "            features = []\n",
    "            for i in range(0, 28, 7):\n",
    "                for j in range(0, 28, 7):\n",
    "                    square = image_array[i:i+7, j:j+7]\n",
    "                    count_zeros = np.sum(square == 1)\n",
    "                    features.append(count_zeros)\n",
    "            \n",
    "            # Flatten the 4x4 feature matrix\n",
    "            features = np.array(features).flatten()\n",
    "            \n",
    "            images.append(features)\n",
    "            image_data = []  # Reset image_data\n",
    "    else:\n",
    "        # Check for start of new image (empty line followed by line with symbols)\n",
    "        if i < len(lines) - 1 and lines[i + 1].decode():  # Check if next line is not empty\n",
    "            image_data = []  # Reset image_data\n",
    "\n",
    "# Convert the list of images to a matrix\n",
    "X_Test = np.array(images)\n",
    "print(X_Test)\n",
    "print(X_Test.shape)  # Should print (number_of_images, 16)\n",
    "\n",
    "fileLab = 'digitdata/testlabels'\n",
    "with open(fileLab, 'rb') as file:\n",
    "    lineLab = file.readlines()\n",
    "labels = []\n",
    "for i, line in enumerate(lineLab):\n",
    "    line = line.decode()\n",
    "    lineSplit= line.split(\"\\n\")\n",
    "    line = \"\".join(lineSplit)\n",
    "    labels.append(int(line))\n",
    "Y_Test = labels\n",
    "print(len(Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomPerceptron:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.zeros((output_size, input_size))\n",
    "        self.bias = np.zeros(output_size)\n",
    "    \n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                # Forward pass\n",
    "                #print(\"X[i]\",len(X[i]))\n",
    "                #print(\"self.weights\",(self.weights.shape))\n",
    "                \"\"\"\n",
    "                print(\"weight updates\")\n",
    "                print(self.weights.shape)\n",
    "                print(\"weights\",self.weights)\n",
    "                print(\"X[i]\",len(X[i]))\n",
    "                #print(X[i].shape)\n",
    "                \"\"\"\n",
    "                weighted_sum = np.dot(self.weights,X[i]) + self.bias\n",
    "                #print(\"weighted_sums\", weighted_sum)\n",
    "                prediction = np.argmax(weighted_sum)\n",
    "                #print(\"Prediction:\",prediction)\n",
    "                \n",
    "                # Weight update based on feature values\n",
    "                #print(\"y[i]\",y[i])\n",
    "                if y[i] != prediction:\n",
    "                    \n",
    "                    #print(\"Prediction weight before:\")\n",
    "                    #print(self.weights[prediction, :])\n",
    "                    self.weights[prediction, :] -= X[i]\n",
    "                    #print(\"Prediction weight after:\")\n",
    "                    #print(self.weights[prediction, :])\n",
    "                    self.bias[prediction] -= 1\n",
    "                    #print(\"Actual weight before:\")\n",
    "                    #print(self.weights[y[i],:])\n",
    "                    self.weights[y[i], :] += X[i]\n",
    "                    #print(\"Actual weight after:\")\n",
    "                    #print(self.weights[y[i], :])\n",
    "                    self.bias[y[i]] += 1\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            weighted_sum = np.dot(self.weights, X[i]) + self.bias\n",
    "            #print(weighted_sum)\n",
    "            prediction = (np.argmax(weighted_sum))\n",
    "            predictions.append(prediction)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:int(X.shape[0]*1.0), :]\n",
    "Y_train = Y[:int(len(Y)*1.0)]\n",
    "X_test = X_Test[:int(X_Test.shape[0]*1.0), :]\n",
    "Y_test = Y_Test[:int(len(Y_Test)*1.0)]\n",
    "#print(X_train)\n",
    "#print(Y_train)\n",
    "#print(X_test)\n",
    "#print(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Accuracy: 56.80%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Custom Perceptron for OCR\n",
    "ocr_perceptron = CustomPerceptron(input_size=16, output_size=10)\n",
    "ocr_perceptron.train(X_train, Y_train, 40)\n",
    "\n",
    "# Predict and evaluate\n",
    "ocr_predictions = ocr_perceptron.predict(X_test)\n",
    "#print(ocr_predictions)\n",
    "CorrectPredictionCount = 0\n",
    "for i in range(len(ocr_predictions)):\n",
    "    if ocr_predictions[i] == Y_test[i]:\n",
    "        #print(\"Prediction:\",ocr_predictions[i],\"Actual:\",Y_test[i])\n",
    "        CorrectPredictionCount += 1\n",
    "Ocr_Accuracy = CorrectPredictionCount/len(ocr_predictions)\n",
    "#ocr_accuracy = np.mean(ocr_predictions == Y_test)\n",
    "print(f'OCR Accuracy: {Ocr_Accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read the file\n",
    "file_path = 'facedata/facedatatrain'  # Replace with the path to your digits file\n",
    "with open(file_path, 'rb') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize variables\n",
    "image_data = []\n",
    "images = []\n",
    "\n",
    "# Parse the lines and populate the list of images\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.decode()  # Convert bytes to string and remove newline character\n",
    "    lineSplit= line.split(\"\\n\")\n",
    "    line = \"\".join(lineSplit)\n",
    "    \n",
    "    # Check for non-empty line\n",
    "    if line:\n",
    "        row_data = [1 if c == '#' else 0 for c in line]  # Convert symbols to pixel values\n",
    "        image_data.append(row_data)\n",
    "        \n",
    "        # Check for end of image (28 lines)\n",
    "        if len(image_data) == 28:\n",
    "            # Convert the list of lists (28x28) to a numpy array\n",
    "            image_array = np.array(image_data)\n",
    "            \n",
    "            # Extract features by counting 0s in each 7x7 square\n",
    "            features = []\n",
    "            for i in range(0, 28, 7):\n",
    "                for j in range(0, 28, 7):\n",
    "                    square = image_array[i:i+7, j:j+7]\n",
    "                    count_zeros = np.sum(square == 1)\n",
    "                    features.append(count_zeros)\n",
    "            \n",
    "            # Flatten the 4x4 feature matrix\n",
    "            features = np.array(features).flatten()\n",
    "            \n",
    "            images.append(features)\n",
    "            image_data = []  # Reset image_data\n",
    "    else:\n",
    "        # Check for start of new image (empty line followed by line with symbols)\n",
    "        if i < len(lines) - 1 and lines[i + 1].decode():  # Check if next line is not empty\n",
    "            image_data = []  # Reset image_data\n",
    "\n",
    "# Convert the list of images to a matrix\n",
    "X = np.array(images)\n",
    "print(X.shape)  # Should print (number_of_images, 16)\n",
    "\n",
    "\n",
    "fileLab = 'digitdata/traininglabels'\n",
    "with open(fileLab, 'rb') as file:\n",
    "    lineLab = file.readlines()\n",
    "labels = []\n",
    "for i, line in enumerate(lineLab):\n",
    "    line = line.decode()\n",
    "    lineSplit= line.split(\"\\n\")\n",
    "    line = \"\".join(lineSplit)\n",
    "    labels.append(int(line))\n",
    "Y = labels\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Detection Example\n",
    "# Assuming you have face detection data (features and labels)\n",
    "# X_face, y_face = load_face_data()  # Load your face detection data\n",
    "\n",
    "# Initialize and train Custom Perceptron for Face Detection\n",
    "face_perceptron = CustomPerceptron(input_size=X_face.shape[1], output_size=2)\n",
    "face_perceptron.train(X_face, y_face)\n",
    "\n",
    "# Predict and evaluate\n",
    "face_predictions = face_perceptron.predict(X_face)\n",
    "face_accuracy = np.mean(face_predictions == y_face)\n",
    "print(f'Face Detection Accuracy: {face_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
