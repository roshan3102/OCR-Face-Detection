{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from feature_extraction import OCR_raw_data, OCR_feature_data, face_raw_data, face_feature_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron Model for OCR and Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.zeros((output_size, input_size))\n",
    "        self.bias = np.zeros(output_size)\n",
    "    \n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                # Forward pass\n",
    "                #print(\"X[i]\",len(X[i]))\n",
    "                #print(\"self.weights\",(self.weights.shape))\n",
    "                \"\"\"\n",
    "                print(\"weight updates\")\n",
    "                print(self.weights.shape)\n",
    "                print(\"weights\",self.weights)\n",
    "                print(\"X[i]\",len(X[i]))\n",
    "                #print(X[i].shape)\n",
    "                \"\"\"\n",
    "                weighted_sum = np.dot(self.weights,X[i]) + self.bias\n",
    "                #print(\"weighted_sums\", weighted_sum)\n",
    "                prediction = np.argmax(weighted_sum)\n",
    "                #print(\"Prediction:\",prediction)\n",
    "                \n",
    "                # Weight update based on feature values\n",
    "                #print(\"y[i]\",y[i])\n",
    "                if y[i] != prediction:\n",
    "                    \n",
    "                    #print(\"Prediction weight before:\")\n",
    "                    #print(self.weights[prediction, :])\n",
    "                    self.weights[prediction, :] -= X[i]\n",
    "                    #print(\"Prediction weight after:\")\n",
    "                    #print(self.weights[prediction, :])\n",
    "                    self.bias[prediction] -= 1\n",
    "                    #print(\"Actual weight before:\")\n",
    "                    #print(self.weights[y[i],:])\n",
    "                    self.weights[y[i], :] += X[i]\n",
    "                    #print(\"Actual weight after:\")\n",
    "                    #print(self.weights[y[i], :])\n",
    "                    self.bias[y[i]] += 1\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            weighted_sum = np.dot(self.weights, X[i]) + self.bias\n",
    "            #print(weighted_sum)\n",
    "            prediction = (np.argmax(weighted_sum))\n",
    "            predictions.append(prediction)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "5000\n",
      "(1000, 784)\n",
      "1000\n",
      "(1000, 784)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "OCRtrainImg = \"digitdata/trainingimages\"\n",
    "OCRtrainLabel = \"digitdata/traininglabels\"\n",
    "\n",
    "OCRvalidImg = \"digitdata/validationimages\"\n",
    "OCRvalidLabel = \"digitdata/validationlabels\"\n",
    "\n",
    "OCRtestImg = \"digitdata/testimages\"\n",
    "OCRtestLabel = \"digitdata/testlabels\"\n",
    "\n",
    "X_train, Y_train = OCR_raw_data(OCRtrainImg, OCRtrainLabel)\n",
    "X_train = X_train[:int(X_train.shape[0]*1.0), :]\n",
    "Y_train = Y_train[:int(len(Y_train)*1.0)]\n",
    "\n",
    "X_valid, Y_valid = OCR_raw_data(OCRvalidImg, OCRvalidLabel)\n",
    "X_valid = X_valid[:int(X_valid.shape[0]*1.0), :]\n",
    "Y_valid = Y_valid[:int(len(Y_valid)*1.0)]\n",
    "\n",
    "X_test, Y_test = OCR_raw_data(OCRtestImg, OCRtestLabel)\n",
    "X_test = X_test[:int(X_test.shape[0]*1.0), :]\n",
    "Y_test = Y_test[:int(len(Y_test)*1.0)]\n",
    "print(X_train.shape)\n",
    "print(len(Y_train))\n",
    "print(X_valid.shape)\n",
    "print(len(Y_valid))\n",
    "print(X_test.shape)\n",
    "print(len(Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Accuracy: 81.50%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Custom Perceptron for OCR\n",
    "ocr_perceptron = Perceptron(input_size=784, output_size=10)\n",
    "ocr_perceptron.train(X_train, Y_train, 40)\n",
    "\n",
    "# Predict and evaluate\n",
    "ocr_predictions = ocr_perceptron.predict(X_valid)\n",
    "\n",
    "CorrectPredictionCount = 0\n",
    "for i in range(len(ocr_predictions)):\n",
    "    if ocr_predictions[i] == Y_valid[i]:\n",
    "        CorrectPredictionCount += 1\n",
    "Ocr_Accuracy = CorrectPredictionCount/len(ocr_predictions)\n",
    "print(f'OCR Accuracy: {Ocr_Accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 4200)\n",
      "45\n",
      "(30, 4200)\n",
      "30\n",
      "(15, 4200)\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "FacetrainImg = \"facedata/facedatatrain\"\n",
    "FacetrainLabel = \"facedata/facedatatrainlabels\"\n",
    "\n",
    "FacevalidImg = \"facedata/facedatavalidation\"\n",
    "FacevalidLabel = \"facedata/facedatavalidationlabels\"\n",
    "\n",
    "FacetestImg = \"facedata/facedatatest\"\n",
    "FacetestLabel = \"facedata/facedatatestlabels\"\n",
    "\n",
    "X_train_face, Y_train_face = face_raw_data(FacetrainImg, FacetrainLabel)\n",
    "X_train_face = X_train_face[:int(X_train_face.shape[0]*0.1), :]\n",
    "Y_train_face = Y_train_face[:int(len(Y_train_face)*0.1)]\n",
    "\n",
    "X_valid_face, Y_valid_face = face_raw_data(FacevalidImg, FacevalidLabel)\n",
    "X_valid_face = X_valid_face[:int(X_valid_face.shape[0]*0.1), :]\n",
    "Y_valid_face = Y_valid_face[:int(len(Y_valid_face)*0.1)]\n",
    "\n",
    "X_test_face, Y_test_face = face_raw_data(FacetestImg, FacetestLabel)\n",
    "X_test_face = X_test_face[:int(X_test_face.shape[0]*0.1), :]\n",
    "Y_test_face = Y_test_face[:int(len(Y_test_face)*0.1)]\n",
    "print(X_train_face.shape)\n",
    "print(len(Y_train_face))\n",
    "print(X_valid_face.shape)\n",
    "print(len(Y_valid_face))\n",
    "print(X_test_face.shape)\n",
    "print(len(Y_test_face))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Accuracy: 70.00%\n"
     ]
    }
   ],
   "source": [
    "face_perceptron = Perceptron(input_size=70*60, output_size=2)\n",
    "face_perceptron.train(X_train_face, Y_train_face, 10)\n",
    "\n",
    "face_predictions = face_perceptron.predict(X_valid_face)\n",
    "\n",
    "CorrectPredictionCount = 0\n",
    "for i in range(len(face_predictions)):\n",
    "    if face_predictions[i] == Y_valid_face[i]:\n",
    "        CorrectPredictionCount += 1\n",
    "Face_Accuracy = CorrectPredictionCount/len(face_predictions)\n",
    "print(f'Face Accuracy: {Face_Accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
