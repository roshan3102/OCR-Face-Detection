{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from feature_extraction import OCR_raw_data, OCR_feature_data, face_raw_data, face_feature_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-Layer Neural Network on digit OCR and Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        W1 = np.random.randn(self.hidden_size, self.input_size)\n",
    "        W1 = W1.flatten()\n",
    "        W2 = np.random.randn(self.output_size, self.hidden_size)\n",
    "        W2 = W2.flatten()\n",
    "        self.weights = np.concatenate((W1,W2))\n",
    "        self.biases = np.array([1,1])\n",
    "        L1_grads = np.zeros((self.hidden_size, self.input_size))\n",
    "        L2_grads = np.zeros((self.output_size, self.hidden_size))\n",
    "        self.gradients = np.concatenate((L1_grads.flatten(),L2_grads.flatten()))\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        W1 = np.reshape(self.weights[0:self.input_size*self.hidden_size],(self.hidden_size,self.input_size))\n",
    "        W2 = np.reshape(self.weights[self.input_size*self.hidden_size:],(self.output_size,self.hidden_size))\n",
    "        b1 = self.biases[0]\n",
    "        b2 = self.biases[1]\n",
    "        # First layer\n",
    "        A1 = X\n",
    "        Z2 = np.dot(W1, A1)+b1\n",
    "        A2 = self.sigmoid(Z2)\n",
    "        \n",
    "        # Second layer\n",
    "        Z3 = np.dot(W2, A2)+b2\n",
    "        A3 = self.sigmoid(Z3)\n",
    "        \n",
    "        cache = {\"Z2\": Z2, \"A2\": A2, \"Z3\": Z3, \"A3\": A3, \"A1\": A1}\n",
    "        \n",
    "        return A3, cache\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def backward_propagation(self, Y, cache):\n",
    "        W2 = np.reshape(self.weights[self.input_size*self.hidden_size:],(self.output_size,self.hidden_size))\n",
    "        A1 = cache[\"A1\"]\n",
    "        A2 = cache[\"A2\"]\n",
    "        A3 = cache[\"A3\"]\n",
    "        y=np.array(Y)\n",
    "        encode_Y = np.eye(self.output_size)[y.astype(int)]\n",
    "        dZ3 = A3 - encode_Y\n",
    "        dZ2 = np.dot(W2.T, dZ3) * (A2 * (1 - A2))\n",
    "        L1_grads = np.reshape(self.gradients[0:self.hidden_size*self.input_size],(self.hidden_size,self.input_size))\n",
    "        L1_grads += dZ2[:, np.newaxis] * A1\n",
    "        L2_grads = np.reshape(self.gradients[self.hidden_size*self.input_size:],(self.output_size,self.hidden_size))\n",
    "        L2_grads += dZ3[:, np.newaxis] * A2\n",
    "        grads = [L1_grads, L2_grads]\n",
    "        return grads    \n",
    "    def update_parameters(self,grads, learning_rate, n):\n",
    "        W1 = np.reshape(self.weights[0:self.input_size*self.hidden_size],(self.hidden_size,self.input_size))\n",
    "        W2 = np.reshape(self.weights[self.input_size*self.hidden_size:],(self.output_size,self.hidden_size))\n",
    "        b1 = self.biases[0]\n",
    "        b2 = self.biases[1]\n",
    "\n",
    "        L1_grads = grads[0]\n",
    "        L2_grads = grads[1]\n",
    "\n",
    "        dW1 = L1_grads/n\n",
    "\n",
    "        dW2 = L2_grads/n\n",
    "\n",
    "        W1 -= learning_rate * dW1\n",
    "        W2 -= learning_rate * dW2\n",
    "        #b1 -= learning_rate * dW1\n",
    "        #b2 -= learning_rate * dW2\n",
    "\n",
    "\n",
    "        self.weights = np.concatenate((W1.flatten(),W2.flatten()))\n",
    "        self.biases[0] = b1\n",
    "        self.biases[1] = b2\n",
    "        self.gradients = np.concatenate((L1_grads.flatten(),L2_grads.flatten()))\n",
    "    \n",
    "    def fit(self, X, Y, num_iterations, learning_rate):\n",
    "        n = len(Y)\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            correct = 0\n",
    "            self.gradients = np.zeros(self.gradients.shape)    \n",
    "            for j in range(X.shape[0]):\n",
    "\n",
    "                x = X[j]\n",
    "                y = Y[j]\n",
    "                A3, cache = self.forward_propagation(x)\n",
    "                if np.argmax(A3) == y:\n",
    "                    correct += 1\n",
    "                    continue\n",
    "              \n",
    "                grads= self.backward_propagation(y, cache)\n",
    "                \n",
    "                self.update_parameters(grads, learning_rate,n)\n",
    "            print(\"Iteration: \", i, \"Accuracy: \", correct/n)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        A3, _ = self.forward_propagation(X)\n",
    "        if self.output_size == 1:\n",
    "            predictions = (A3 > 0.5).astype(int)\n",
    "        else:\n",
    "            predictions = np.argmax(A3, axis=0)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "5000\n",
      "(1000, 784)\n",
      "1000\n",
      "(1000, 784)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "OCRtrainImg = \"digitdata/trainingimages\"\n",
    "OCRtrainLabel = \"digitdata/traininglabels\"\n",
    "\n",
    "OCRvalidImg = \"digitdata/validationimages\"\n",
    "OCRvalidLabel = \"digitdata/validationlabels\"\n",
    "\n",
    "OCRtestImg = \"digitdata/testimages\"\n",
    "OCRtestLabel = \"digitdata/testlabels\"\n",
    "\n",
    "X_train, Y_train = OCR_raw_data(OCRtrainImg, OCRtrainLabel)\n",
    "X_train = X_train[:int(X_train.shape[0]*1.0), :]\n",
    "Y_train = Y_train[:int(len(Y_train)*1.0)]\n",
    "\n",
    "X_valid, Y_valid = OCR_raw_data(OCRvalidImg, OCRvalidLabel)\n",
    "X_valid = X_valid[:int(X_valid.shape[0]*1.0), :]\n",
    "Y_valid = Y_valid[:int(len(Y_valid)*1.0)]\n",
    "\n",
    "X_test, Y_test = OCR_raw_data(OCRtestImg, OCRtestLabel)\n",
    "X_test = X_test[:int(X_test.shape[0]*1.0), :]\n",
    "Y_test = Y_test[:int(len(Y_test)*1.0)]\n",
    "\n",
    "\n",
    "#X_train, Y_train = OCR_feature_data(OCRtrainImg, OCRtrainLabel, 7, 7)\n",
    "#X_train = X_train[:int(X_train.shape[0]*1), :]\n",
    "#Y_train = Y_train[:int(len(Y_train)*1)]\n",
    "\n",
    "#X_valid, Y_valid = OCR_feature_data(OCRvalidImg, OCRvalidLabel,7,7)\n",
    "#X_valid = X_valid[:int(X_valid.shape[0]*1), :]\n",
    "#Y_valid = Y_valid[:int(len(Y_valid)*1)]\n",
    "\n",
    "#X_test, Y_test = OCR_feature_data(OCRtestImg, OCRtestLabel,7 ,7)\n",
    "#X_test = X_test[:int(X_test.shape[0]*1), :]\n",
    "#Y_test = Y_test[:int(len(Y_test)*1)]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(len(Y_train))\n",
    "print(X_valid.shape)\n",
    "print(len(Y_valid))\n",
    "print(X_test.shape)\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 Accuracy:  0.1542\n",
      "Iteration:  1 Accuracy:  0.3206\n",
      "Iteration:  2 Accuracy:  0.4474\n",
      "Iteration:  3 Accuracy:  0.5198\n",
      "Iteration:  4 Accuracy:  0.5678\n",
      "Iteration:  5 Accuracy:  0.605\n",
      "Iteration:  6 Accuracy:  0.6398\n",
      "Iteration:  7 Accuracy:  0.6604\n",
      "Iteration:  8 Accuracy:  0.665\n",
      "Iteration:  9 Accuracy:  0.6832\n",
      "Iteration:  10 Accuracy:  0.683\n",
      "Iteration:  11 Accuracy:  0.6946\n",
      "Iteration:  12 Accuracy:  0.699\n",
      "Iteration:  13 Accuracy:  0.7078\n",
      "Iteration:  14 Accuracy:  0.7084\n",
      "Iteration:  15 Accuracy:  0.7186\n",
      "Iteration:  16 Accuracy:  0.7196\n",
      "Iteration:  17 Accuracy:  0.7262\n",
      "Iteration:  18 Accuracy:  0.7274\n",
      "Iteration:  19 Accuracy:  0.7358\n",
      "[7, 2, 1, 0, 2, 1, 4, 7, 2, 9, 0, 2, 9, 0, 1, 3, 9, 7, 3, 4, 9, 6, 2, 5, 4, 0, 7, 9, 0, 1, 3, 5, 3, 2, 7, 2, 7, 1, 2, 1, 1, 7, 9, 2, 6, 3, 3, 2, 9, 9, 6, 3, 5, 6, 4, 0, 4, 3, 4, 5, 7, 5, 9, 2, 2, 4, 6, 4, 3, 0, 7, 0, 5, 9, 1, 7, 3, 7, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 6, 3, 3, 6, 9]\n",
      "OCR Accuracy: 62.60%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Custom Perceptron for OCR\n",
    "ocr_NN = TwoLayerNN(input_size=784,hidden_size=50, output_size=10)\n",
    "ocr_NN.fit(X_train, Y_train, 20,0.01)\n",
    "\n",
    "# Predict and evaluate\n",
    "ocr_predictions = []\n",
    "for i in range(X_valid.shape[0]):\n",
    "    ocr_predictions.append(ocr_NN.predict(X_valid[i]))\n",
    "#ocr_predictions = ocr_NN.predict(X_valid)\n",
    "print(ocr_predictions[0:100])\n",
    "CorrectPredictionCount = 0\n",
    "for i in range(len(ocr_predictions)):\n",
    "    if ocr_predictions[i] == Y_valid[i]:\n",
    "        CorrectPredictionCount += 1\n",
    "Ocr_Accuracy = CorrectPredictionCount/len(ocr_predictions)\n",
    "print(f'OCR Accuracy: {Ocr_Accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 4200)\n",
      "451\n",
      "(301, 4200)\n",
      "301\n",
      "(150, 4200)\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "FacetrainImg = \"facedata/facedatatrain\"\n",
    "FacetrainLabel = \"facedata/facedatatrainlabels\"\n",
    "FacevalidImg = \"facedata/facedatavalidation\"\n",
    "FacevalidLabel = \"facedata/facedatavalidationlabels\"\n",
    "FacetestImg = \"facedata/facedatatest\"\n",
    "FacetestLabel = \"facedata/facedatatestlabels\"\n",
    "\n",
    "X_train, Y_train = face_raw_data(FacetrainImg, FacetrainLabel)\n",
    "X_train = X_train[:int(X_train.shape[0]*1.0), :]\n",
    "Y_train = Y_train[:int(len(Y_train)*1.0)]\n",
    "\n",
    "X_valid, Y_valid = face_raw_data(FacevalidImg, FacevalidLabel)\n",
    "X_valid = X_valid[:int(X_valid.shape[0]*1.0), :]\n",
    "Y_valid = Y_valid[:int(len(Y_valid)*1.0)]\n",
    "\n",
    "X_test, Y_test = face_raw_data(FacetestImg, FacetestLabel)\n",
    "X_test = X_test[:int(X_test.shape[0]*1.0), :]\n",
    "Y_test = Y_test[:int(len(Y_test)*1.0)]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(len(Y_train))\n",
    "print(X_valid.shape)\n",
    "print(len(Y_valid))\n",
    "print(X_test.shape)\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 Accuracy:  0.47671840354767187\n",
      "Iteration:  1 Accuracy:  0.4678492239467849\n",
      "Iteration:  2 Accuracy:  0.5033259423503326\n",
      "Iteration:  3 Accuracy:  0.5033259423503326\n",
      "Iteration:  4 Accuracy:  0.532150776053215\n",
      "Iteration:  5 Accuracy:  0.516629711751663\n",
      "Iteration:  6 Accuracy:  0.5454545454545454\n",
      "Iteration:  7 Accuracy:  0.5343680709534369\n",
      "Iteration:  8 Accuracy:  0.5631929046563193\n",
      "Iteration:  9 Accuracy:  0.5521064301552107\n",
      "Iteration:  10 Accuracy:  0.5809312638580931\n",
      "Iteration:  11 Accuracy:  0.5831485587583148\n",
      "Iteration:  12 Accuracy:  0.5986696230598669\n",
      "Iteration:  13 Accuracy:  0.5920177383592018\n",
      "Iteration:  14 Accuracy:  0.6031042128603105\n",
      "Iteration:  15 Accuracy:  0.6031042128603105\n",
      "Iteration:  16 Accuracy:  0.614190687361419\n",
      "Iteration:  17 Accuracy:  0.6097560975609756\n",
      "Iteration:  18 Accuracy:  0.6297117516629712\n",
      "Iteration:  19 Accuracy:  0.6297117516629712\n",
      "[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]\n",
      "Face Accuracy: 51.50%\n"
     ]
    }
   ],
   "source": [
    "face_nn = TwoLayerNN(input_size=70*60, hidden_size=50, output_size=2)\n",
    "face_nn.fit(X_train, Y_train, 20, 0.01)\n",
    "\n",
    "face_predictions = []\n",
    "for i in range(X_valid.shape[0]):\n",
    "    face_predictions.append(face_nn.predict(X_valid[i]))\n",
    "print(face_predictions[0:100])\n",
    "CorrectPredictionCount = 0\n",
    "for i in range(len(face_predictions)):\n",
    "    if face_predictions[i] == Y_valid[i]:\n",
    "        CorrectPredictionCount += 1\n",
    "Face_Accuracy = CorrectPredictionCount/len(face_predictions)\n",
    "print(f'Face Accuracy: {Face_Accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
